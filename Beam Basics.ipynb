{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kata1.: Your first kata is to create a simple pipeline that takes a hardcoded input element \"Hello Beam\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Beam\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(['Hello Beam'])\n",
    "       | beam.Map(print))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ParDo is a Beam transform for generic parallel processing. The ParDo processing paradigm is similar to the “Map” phase of a Map/Shuffle/Reduce-style algorithm: a ParDo transform considers each element in the input PCollection, performs some processing function (your user code) on that element, and emits zero, one, or multiple elements to an output PCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ParDo\n",
    "Kata2: Please write a simple ParDo that maps the input element by multiplying it by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "class MultiplyByTenDoFn(beam.DoFn):\n",
    "\n",
    "    def process(self,element):\n",
    "        return [10*element]\n",
    "\n",
    "\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create([1, 2, 3, 4, 5])\n",
    "       | beam.ParDo(MultiplyByTenDoFn())\n",
    "       | beam.Map(print))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ParDo OneToMany\n",
    "\n",
    "Kata3: Please write a ParDo that maps each input sentence into words tokenized by whitespace (\" \")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Beam\n",
      "It\n",
      "is\n",
      "awesome\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class BreakIntoWordsDoFn(beam.DoFn):\n",
    "    def process(self,element):\n",
    "        return element.split(\" \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(['Hello Beam', 'It is awesome'])\n",
    "       | beam.ParDo(BreakIntoWordsDoFn())\n",
    "       | beam.Map(print))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapElements\n",
    "The Beam SDKs provide language-specific ways to simplify how you provide your DoFn implementation.\n",
    "\n",
    "Kata4: Implement a simple map function that multiplies all input elements by 5 using Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create([10, 20, 30, 40, 50])\n",
    "     | beam.Map(lambda x: 5*x)\n",
    "     |  beam.Map(print))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FlatMapElements\n",
    "The Beam SDKs provide language-specific ways to simplify how you provide your DoFn implementation.\n",
    "\n",
    "FlatMap can be used to simplify DoFn that maps an element to multiple elements (one to many).\n",
    "\n",
    "Kata5: Implement a function that maps each input sentence into words tokenized by whitespace (\" \") using FlatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache\n",
      "Beam\n",
      "Unified\n",
      "Batch\n",
      "and\n",
      "Streaming\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(['Apache Beam', 'Unified Batch and Streaming'])\n",
    "     | beam.FlatMap(lambda x: x.split(\" \"))\n",
    "     | beam.Map(print))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GroupByKey\n",
    "GroupByKey is a Beam transform for processing collections of key/value pairs. It’s a parallel reduction operation, analogous to the Shuffle phase of a Map/Shuffle/Reduce-style algorithm. The input to GroupByKey is a collection of key/value pairs that represents a multimap, where the collection contains multiple pairs that have the same key, but different values. Given such a collection, you use GroupByKey to collect all of the values associated with each unique key.\n",
    "\n",
    "Kata6: Implement a GroupByKey transform that groups words by its first letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', ['apple', 'ant'])\n",
      "('b', ['ball', 'bear'])\n",
      "('c', ['car', 'cheetah'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(['apple', 'ball', 'car', 'bear', 'cheetah', 'ant'])\n",
    "     | beam.GroupBy(lambda x:x[0])\n",
    "     | beam.Map(print))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine - Simple Function\n",
    "Combine is a Beam transform for combining collections of elements or values in your data. When you apply a Combine transform, you must provide the function that contains the logic for combining the elements or values. The combining function should be commutative and associative, as the function is not necessarily invoked exactly once on all values with a given key. Because the input data (including the value collection) may be distributed across multiple workers, the combining function might be called multiple times to perform partial combining on subsets of the value collection.\n",
    "\n",
    "Simple combine operations, such as sums, can usually be implemented as a simple function.\n",
    "\n",
    "Kata7: Implement the summation of numbers using CombineGlobally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "def sum(numbers):\n",
    "    j=0\n",
    "    for i in numbers:\n",
    "        j=j+i\n",
    "\n",
    "    return j\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create([1, 2, 3, 4, 5])\n",
    "     | beam.CombineGlobally(sum)\n",
    "     | beam.Map(print))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine - Combine PerKey\n",
    "After creating a keyed PCollection (for example, by using a GroupByKey transform), a common pattern is to combine the collection of values associated with each key into a single, merged value. This pattern of a GroupByKey followed by merging the collection of values is equivalent to Combine PerKey transform. The combine function you supply to Combine PerKey must be an associative reduction function or a subclass of CombineFn.\n",
    "\n",
    "Kata8: Implement the sum of scores per player using CombinePerKey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Player 1', 115)\n",
      "('Player 2', 85)\n",
      "('Player 3', 25)\n"
     ]
    }
   ],
   "source": [
    "PLAYER_1 = 'Player 1'\n",
    "PLAYER_2 = 'Player 2'\n",
    "PLAYER_3 = 'Player 3'\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create([(PLAYER_1, 15), (PLAYER_2, 10), (PLAYER_1, 100),\n",
    "                    (PLAYER_3, 25), (PLAYER_2, 75)])\n",
    "     | beam.CombinePerKey(sum)\n",
    "     |  beam.Map(print))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten\n",
    "Flatten is a Beam transform for PCollection objects that store the same data type. Flatten merges multiple PCollection objects into a single logical PCollection.\n",
    "\n",
    "Kata9: Implement a Flatten transform that merges two PCollection of words into a single PCollection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n",
      "ant\n",
      "arrow\n",
      "ball\n",
      "book\n",
      "bow\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "    wordsStartingWithA =   p | 'Words starting with A' >> beam.Create(['apple', 'ant', 'arrow'])\n",
    "    wordsStartingWithB =   p | 'Words starting with B' >> beam.Create(['ball', 'book', 'bow'])\n",
    "    ((wordsStartingWithA,wordsStartingWithB)\n",
    "    | beam.Flatten()\n",
    "    | beam.Map(print))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Branching\n",
    "You can use the same PCollection as input for multiple transforms without consuming the input or altering it.\n",
    "\n",
    "Kata10: Branch out the numbers to two different transforms: one transform is multiplying each number by 5 and the other transform is multiplying each number by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-36-ed8d0573f2cc>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-ed8d0573f2cc>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    mult10_results = numbers| beam.ParDo(MultiplyByTenDoFn())\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class MultiplyByTenDoFn(beam.DoFn):\n",
    "\n",
    "    def process(self,element):\n",
    "        return [10*element]\n",
    "class MultiplyByFiveDoFn(beam.DoFn):\n",
    "\n",
    "    def process(self,element):\n",
    "        return [5*element]\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    numbers = p | beam.Create([1, 2, 3, 4, 5])\n",
    "    mult5_results = numbers| beam.ParDo(MultiplyByFiveDoFn()\n",
    "    mult10_results = numbers| beam.ParDo(MultiplyByTenDoFn())\n",
    "\n",
    "                                        \n",
    "                    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Composite Transform\n",
    "Transforms can have a nested structure, where a complex transform performs multiple simpler transforms (such as more than one ParDo, Combine, GroupByKey, or even other composite transforms). These transforms are called composite transforms. Nesting multiple transforms inside a single composite transform can make your code more modular and easier to understand.\n",
    "\n",
    "To create your own composite transform, create a subclass of the PTransform class and override the expand method to specify the actual processing logic. You can then use this transform just as you would a built-in transform from the Beam SDK. Within your PTransform subclass, you’ll need to override the expand method. The expand method is where you add the processing logic for the PTransform. Your override of expand must accept the appropriate type of input PCollection as a parameter, and specify the output PCollection as the return value.\n",
    "\n",
    "Kata11: Please implement a composite transform \"ExtractAndMultiplyNumbers\" that extracts numbers from comma separated line and then multiplies each number by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "class ExtractAndMultiplyNumbers(beam.PTransform):\n",
    "    def expand(self,pcoll):\n",
    "        return pcoll | beam.FlatMap(lambda line: map(int, line.split(','))) | beam.Map(lambda x:10*x)\n",
    "\n",
    "\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(['1,2,3,4,5', '6,7,8,9,10'])\n",
    "     | ExtractAndMultiplyNumbers()\n",
    "     | beam.Map(print))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter using ParDo\n",
    "\n",
    "Kata12: Implement a filter function that filters out the even numbers by using ParDo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "class FilterOutEvenNumber(beam.PTransform):\n",
    "    def expand(self,pcoll):\n",
    "        return pcoll | beam.Filter(lambda x: x%2==0)\n",
    "\n",
    "\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(range(1, 11))\n",
    "       | FilterOutEvenNumber()\n",
    "       | beam.Map(print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "class FilterOutEvenNumber(beam.DoFn):\n",
    "    def process(self,element):\n",
    "        if element%2!=1:\n",
    "            yield element\n",
    "\n",
    "\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(range(1, 11))\n",
    "     | beam.ParDo(FilterOutEvenNumber())\n",
    "     | beam.Map(print))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter\n",
    "The Beam SDKs provide language-specific ways to simplify how you provide your DoFn implementation.\n",
    "\n",
    "Kata13: Implement a filter function that filters out the odd numbers by using Filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(range(1, 11))\n",
    "     | beam.Filter(lambda x: x%2!=0)\n",
    "     | beam.Map(print))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation - Count\n",
    "\n",
    "Kata14: Count the number of elements from an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(range(1, 11))\n",
    "     | beam.combiners.Count.Globally()\n",
    "     | beam.Map(print))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation - Sum\n",
    "\n",
    "Kata15 : Compute the sum of all elements from an input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation - Sum\n",
    "\n",
    "Kata15: Compute the sum of all elements from an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(range(1, 11))\n",
    "     | beam.CombineGlobally(sum)\n",
    "     | beam.Map(print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "class sumall(beam.DoFn):\n",
    "\n",
    "    def process(self,element):\n",
    "        s=0\n",
    "        element=element+s\n",
    "        return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(range(1, 11))\n",
    "     | beam.CombineGlobally(sum)\n",
    "     | beam.Map(print))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation - Mean\n",
    "\n",
    "Kata16: Compute the mean/average of all elements from an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(range(1, 11))\n",
    "     | beam.combiners.Mean.Globally()\n",
    "     | beam.Map(print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WithKeys\n",
    "\n",
    "Kata17: Convert each fruit name into a key/value pair of its first letter and itself, e.g. apple => ('a', 'apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'apple')\n",
      "('b', 'banana')\n",
      "('c', 'cherry')\n",
      "('d', 'durian')\n",
      "('g', 'guava')\n",
      "('m', 'melon')\n"
     ]
    }
   ],
   "source": [
    "def myfunc(text):\n",
    "    return (text[0],text)\n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(['apple', 'banana', 'cherry', 'durian', 'guava', 'melon'])\n",
    "     | beam.Map(myfunc)\n",
    "     | beam.Map(print))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "23b4a3e8622309bcc6db3d5cc6eb73d60ab98d9ec23bad6a26b709981ccb403a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
